{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from nbeats_forecast import NBeats\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| N-Beats\n",
      "| --  Stack Generic (#0) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=7, backcast_length=582, forecast_length=194, share_thetas=False) at @1745205044992\n",
      "     | -- GenericBlock(units=128, thetas_dim=7, backcast_length=582, forecast_length=194, share_thetas=False) at @1745205045808\n",
      "     | -- GenericBlock(units=128, thetas_dim=7, backcast_length=582, forecast_length=194, share_thetas=False) at @1745205046096\n",
      "| --  Stack Generic (#1) (share_weights_in_stack=False)\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=582, forecast_length=194, share_thetas=False) at @1745205044512\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=582, forecast_length=194, share_thetas=False) at @1745205046288\n",
      "     | -- GenericBlock(units=128, thetas_dim=8, backcast_length=582, forecast_length=194, share_thetas=False) at @1745205046384\n",
      "grad_step = 000210, tr_loss = 0.001082, te_loss = 0.479394\n",
      "grad_step = 000240, tr_loss = 0.000742, te_loss = 0.479394\n",
      "grad_step = 000270, tr_loss = 0.000451, te_loss = 0.479394\n",
      "grad_step = 000300, tr_loss = 0.000271, te_loss = 0.479394\n",
      "grad_step = 000330, tr_loss = 0.000111, te_loss = 0.007207\n",
      "grad_step = 000360, tr_loss = 0.000098, te_loss = 0.007207\n",
      "grad_step = 000390, tr_loss = 0.000040, te_loss = 0.007207\n",
      "grad_step = 000420, tr_loss = 0.000007, te_loss = 0.007440\n",
      "grad_step = 000450, tr_loss = 0.000003, te_loss = 0.007440\n",
      "grad_step = 000480, tr_loss = 0.000001, te_loss = 0.007440\n",
      "grad_step = 000510, tr_loss = 0.000114, te_loss = 0.007828\n",
      "grad_step = 000540, tr_loss = 0.000004, te_loss = 0.007828\n",
      "grad_step = 000570, tr_loss = 0.000000, te_loss = 0.007828\n",
      "grad_step = 000600, tr_loss = 0.000000, te_loss = 0.007828\n",
      "grad_step = 000630, tr_loss = 0.000000, te_loss = 0.007556\n",
      "grad_step = 000660, tr_loss = 0.000061, te_loss = 0.007556\n",
      "grad_step = 000690, tr_loss = 0.000025, te_loss = 0.007556\n",
      "grad_step = 000720, tr_loss = 0.000001, te_loss = 0.007529\n",
      "grad_step = 000750, tr_loss = 0.000000, te_loss = 0.007529\n",
      "grad_step = 000780, tr_loss = 0.000107, te_loss = 0.007529\n",
      "grad_step = 000810, tr_loss = 0.000007, te_loss = 0.007540\n",
      "grad_step = 000840, tr_loss = 0.000000, te_loss = 0.007540\n",
      "grad_step = 000870, tr_loss = 0.000000, te_loss = 0.007540\n",
      "grad_step = 000900, tr_loss = 0.000000, te_loss = 0.007540\n",
      "grad_step = 000930, tr_loss = 0.000244, te_loss = 0.007544\n",
      "grad_step = 000960, tr_loss = 0.000013, te_loss = 0.007544\n",
      "grad_step = 000990, tr_loss = 0.000000, te_loss = 0.007544\n",
      "grad_step = 001020, tr_loss = 0.000000, te_loss = 0.007568\n",
      "grad_step = 001050, tr_loss = 0.000000, te_loss = 0.007568\n",
      "grad_step = 001080, tr_loss = 0.000000, te_loss = 0.007568\n",
      "grad_step = 001110, tr_loss = 0.000000, te_loss = 0.007574\n",
      "grad_step = 001140, tr_loss = 0.000000, te_loss = 0.007574\n",
      "grad_step = 001170, tr_loss = 0.000018, te_loss = 0.007574\n",
      "grad_step = 001200, tr_loss = 0.000006, te_loss = 0.007574\n",
      "grad_step = 001230, tr_loss = 0.000000, te_loss = 0.007626\n",
      "grad_step = 001260, tr_loss = 0.000000, te_loss = 0.007626\n",
      "grad_step = 001290, tr_loss = 0.000067, te_loss = 0.007626\n",
      "grad_step = 001320, tr_loss = 0.000000, te_loss = 0.007543\n",
      "grad_step = 001350, tr_loss = 0.000000, te_loss = 0.007543\n",
      "grad_step = 001380, tr_loss = 0.000000, te_loss = 0.007543\n",
      "grad_step = 001410, tr_loss = 0.000000, te_loss = 0.007542\n",
      "grad_step = 001440, tr_loss = 0.000000, te_loss = 0.007542\n",
      "grad_step = 001470, tr_loss = 0.000007, te_loss = 0.007542\n",
      "grad_step = 001500, tr_loss = 0.000001, te_loss = 0.007542\n",
      "grad_step = 001530, tr_loss = 0.000000, te_loss = 0.007579\n",
      "grad_step = 001560, tr_loss = 0.000000, te_loss = 0.007579\n",
      "grad_step = 001590, tr_loss = 0.000000, te_loss = 0.007579\n",
      "grad_step = 001620, tr_loss = 0.000000, te_loss = 0.007584\n",
      "grad_step = 001650, tr_loss = 0.000000, te_loss = 0.007584\n",
      "grad_step = 001680, tr_loss = 0.000000, te_loss = 0.007584\n",
      "grad_step = 001710, tr_loss = 0.000000, te_loss = 0.007584\n",
      "grad_step = 001740, tr_loss = 0.000000, te_loss = 0.007584\n",
      "grad_step = 001770, tr_loss = 0.000064, te_loss = 0.007584\n",
      "grad_step = 001800, tr_loss = 0.000005, te_loss = 0.007584\n",
      "grad_step = 001830, tr_loss = 0.000001, te_loss = 0.007693\n",
      "grad_step = 001860, tr_loss = 0.000000, te_loss = 0.007693\n",
      "grad_step = 001890, tr_loss = 0.000000, te_loss = 0.007693\n",
      "grad_step = 001920, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 001950, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 001980, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 002010, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 002040, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 002070, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 002100, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 002130, tr_loss = 0.000000, te_loss = 0.007583\n",
      "grad_step = 002160, tr_loss = 0.000216, te_loss = 0.007583\n",
      "grad_step = 002190, tr_loss = 0.000011, te_loss = 0.007583\n",
      "grad_step = 002220, tr_loss = 0.000000, te_loss = 0.007707\n",
      "grad_step = 002250, tr_loss = 0.000000, te_loss = 0.007707\n",
      "grad_step = 002280, tr_loss = 0.000000, te_loss = 0.007707\n",
      "grad_step = 002310, tr_loss = 0.000000, te_loss = 0.007662\n",
      "grad_step = 002340, tr_loss = 0.000000, te_loss = 0.007662\n",
      "grad_step = 002370, tr_loss = 0.000000, te_loss = 0.007662\n",
      "grad_step = 002400, tr_loss = 0.000000, te_loss = 0.007662\n",
      "grad_step = 002430, tr_loss = 0.000000, te_loss = 0.007663\n",
      "grad_step = 002460, tr_loss = 0.000000, te_loss = 0.007663\n",
      "grad_step = 002490, tr_loss = 0.000000, te_loss = 0.007663\n",
      "grad_step = 002520, tr_loss = 0.000000, te_loss = 0.007663\n",
      "grad_step = 002550, tr_loss = 0.000000, te_loss = 0.007663\n",
      "grad_step = 002580, tr_loss = 0.000007, te_loss = 0.007663\n",
      "grad_step = 002610, tr_loss = 0.000013, te_loss = 0.007328\n",
      "grad_step = 002640, tr_loss = 0.000001, te_loss = 0.007328\n",
      "grad_step = 002670, tr_loss = 0.000000, te_loss = 0.007328\n",
      "grad_step = 002700, tr_loss = 0.000000, te_loss = 0.007328\n"
     ]
    }
   ],
   "source": [
    "file = \"C:/Users/gurpr/Videos/BetaSci/Rossmann_Store1_Data_FULL_NBeats.csv\"\n",
    "pwd = os.getcwd()\n",
    "os.chdir(os.path.dirname(file))\n",
    "data = pd.read_csv(os.path.basename(file))\n",
    "data = data.values        #univariate time series data of shape nx1 (numpy array)\n",
    "\n",
    "#nparray = data[\"Sale\"].to_numpy()\n",
    "#model = NBeats(data=data, period_to_forecast=194, train_percent=0.75)\n",
    "model = NBeats(data=data, period_to_forecast=194, train_percent=0.75)\n",
    "model.fit()\n",
    "forecast = model.predict()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'ta'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-a9efbc243647>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0my_test\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mdata\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mta\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mrmse\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmean_squared_error\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0my_test\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mforecast\u001B[0m \u001B[1;33m,\u001B[0m \u001B[0msquared\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;32mFalse\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'numpy.ndarray' object has no attribute 'ta'"
     ]
    }
   ],
   "source": [
    "y_test = data.ta\n",
    "rmse = mean_squared_error(y_test, forecast , squared=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6530.8955]\n",
      " [6009.882 ]\n",
      " [5330.859 ]\n",
      " [4571.4707]\n",
      " [4550.2505]\n",
      " [4987.7583]\n",
      " [5102.5195]\n",
      " [6271.6387]\n",
      " [7483.38  ]\n",
      " [7812.347 ]\n",
      " [7503.7   ]\n",
      " [7443.582 ]\n",
      " [7589.7065]\n",
      " [7714.53  ]\n",
      " [8984.557 ]\n",
      " [8499.685 ]\n",
      " [5433.928 ]\n",
      " [4949.632 ]\n",
      " [6208.8457]\n",
      " [6463.481 ]\n",
      " [4144.8657]\n",
      " [4249.9014]\n",
      " [5081.402 ]\n",
      " [5730.4   ]\n",
      " [5101.282 ]\n",
      " [4550.5264]\n",
      " [4053.1577]\n",
      " [3838.2644]\n",
      " [4364.6875]\n",
      " [5080.3823]\n",
      " [5084.009 ]\n",
      " [4670.44  ]\n",
      " [4221.135 ]\n",
      " [4171.6074]\n",
      " [4801.668 ]\n",
      " [4201.382 ]\n",
      " [3638.6233]\n",
      " [3402.7778]\n",
      " [3537.459 ]\n",
      " [3550.7266]\n",
      " [4366.493 ]\n",
      " [4666.265 ]\n",
      " [4837.196 ]\n",
      " [4397.3716]\n",
      " [4635.7065]\n",
      " [5269.381 ]\n",
      " [5336.    ]\n",
      " [5485.7007]\n",
      " [5215.653 ]\n",
      " [4684.559 ]\n",
      " [4429.54  ]\n",
      " [4690.9053]\n",
      " [4634.437 ]\n",
      " [4183.2446]\n",
      " [3441.771 ]\n",
      " [3440.882 ]\n",
      " [3734.335 ]\n",
      " [4366.3384]\n",
      " [4858.8994]\n",
      " [4609.0513]\n",
      " [4442.414 ]\n",
      " [4344.8115]\n",
      " [4264.7266]\n",
      " [4533.24  ]\n",
      " [4561.274 ]\n",
      " [3992.4868]\n",
      " [3777.161 ]\n",
      " [3808.6995]\n",
      " [3986.0476]\n",
      " [4438.153 ]\n",
      " [5103.775 ]\n",
      " [5756.3813]\n",
      " [5600.8467]\n",
      " [5546.0977]\n",
      " [4712.059 ]\n",
      " [4736.1943]\n",
      " [4868.06  ]\n",
      " [4103.42  ]\n",
      " [3807.8499]\n",
      " [4032.6277]\n",
      " [3478.3113]\n",
      " [3427.7673]\n",
      " [4501.928 ]\n",
      " [5361.1646]\n",
      " [5314.059 ]\n",
      " [4183.888 ]\n",
      " [4326.7173]\n",
      " [4317.1846]\n",
      " [3962.0518]\n",
      " [3721.1772]\n",
      " [3551.611 ]\n",
      " [3604.0398]\n",
      " [3710.961 ]\n",
      " [3913.4312]\n",
      " [4818.278 ]\n",
      " [5994.7437]\n",
      " [6351.023 ]\n",
      " [6377.0967]\n",
      " [6693.176 ]\n",
      " [6527.4614]\n",
      " [5259.919 ]\n",
      " [4097.033 ]\n",
      " [3831.3733]\n",
      " [3640.6084]\n",
      " [3743.6965]\n",
      " [4743.149 ]\n",
      " [4951.1353]\n",
      " [4369.294 ]\n",
      " [4093.6746]\n",
      " [4535.817 ]\n",
      " [4631.258 ]\n",
      " [3972.3062]\n",
      " [3404.382 ]\n",
      " [3130.766 ]\n",
      " [3228.3606]\n",
      " [3091.8196]\n",
      " [3944.9082]\n",
      " [4926.175 ]\n",
      " [5268.7866]\n",
      " [5508.7734]\n",
      " [5937.106 ]\n",
      " [5786.635 ]\n",
      " [5573.3486]\n",
      " [5047.2246]\n",
      " [4692.591 ]\n",
      " [4646.731 ]\n",
      " [4478.4727]\n",
      " [4731.5938]\n",
      " [4030.8748]\n",
      " [3559.5881]\n",
      " [3799.119 ]\n",
      " [4030.507 ]\n",
      " [4394.421 ]\n",
      " [4968.309 ]\n",
      " [5225.936 ]\n",
      " [4669.627 ]\n",
      " [4069.8506]\n",
      " [3940.2341]\n",
      " [4350.7017]\n",
      " [4186.8364]\n",
      " [4091.6794]\n",
      " [3927.469 ]\n",
      " [4304.2715]\n",
      " [5086.036 ]\n",
      " [5726.428 ]\n",
      " [5421.2617]\n",
      " [5547.2686]\n",
      " [5457.679 ]\n",
      " [4737.5303]\n",
      " [3973.1848]\n",
      " [3888.6675]\n",
      " [3732.7776]\n",
      " [3596.9028]\n",
      " [3591.4724]\n",
      " [3895.348 ]\n",
      " [5016.886 ]\n",
      " [5083.852 ]\n",
      " [4421.609 ]\n",
      " [4394.6475]\n",
      " [4389.162 ]\n",
      " [4146.5015]\n",
      " [4003.0967]\n",
      " [3787.9634]\n",
      " [3478.4683]\n",
      " [3286.2402]\n",
      " [3354.5642]\n",
      " [3720.837 ]\n",
      " [4555.9526]\n",
      " [5495.6953]\n",
      " [5506.668 ]\n",
      " [5142.9507]\n",
      " [5069.38  ]\n",
      " [4581.603 ]\n",
      " [4495.472 ]\n",
      " [3852.391 ]\n",
      " [3636.538 ]\n",
      " [3666.8506]\n",
      " [3902.698 ]\n",
      " [3678.971 ]\n",
      " [4377.1973]\n",
      " [5050.3975]\n",
      " [4921.036 ]\n",
      " [4678.1167]\n",
      " [4631.982 ]\n",
      " [4512.5166]\n",
      " [4272.0522]\n",
      " [3734.991 ]\n",
      " [3410.9675]\n",
      " [3527.7493]\n",
      " [3773.1855]\n",
      " [3964.2988]\n",
      " [5262.3594]\n",
      " [5610.1255]\n",
      " [4710.988 ]]\n"
     ]
    }
   ],
   "source": [
    "print(forecast)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "out = np.array(forecast, dtype=int)\n",
    "out.round()\n",
    "print(out)\n",
    "np.savetxt(r\"C:\\Users\\gurpr\\Videos\\BetaSci\\NBeats_Pred194Using0.75.csv\", out, delimiter=\",\", fmt='%.0i')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (BetaSci)",
   "language": "python",
   "name": "pycharm-6936f044"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}