{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install the libraries\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import EarlyStopping\n",
    "#from pytorch_forecasting import TimeSeriesDataSet, NBeats, Baseline\n",
    "from pytorch_forecasting.data import NaNLabelEncoder\n",
    "from pytorch_forecasting.data.examples import generate_ar_data\n",
    "from pytorch_forecasting.metrics import SMAPE\n",
    "from nbeats_forecast import NBeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "my_early_stop_callback = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        min_delta=0.00,\n",
    "        patience=3,\n",
    "        verbose=False,\n",
    "        mode='min',\n",
    "        strict=True\n",
    "    )"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "   Sale\n0  4327\n1  4486\n2  4997\n3  7176\n4  5580",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Sale</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4327</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>4486</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4997</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>7176</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5580</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = \"C:/Users/gurpr/Videos/BetaSci/Rossmann_Store1_Data_FULL.csv\"\n",
    "pwd = os.getcwd()\n",
    "os.chdir(os.path.dirname(file))\n",
    "df = pd.read_csv(os.path.basename(file), usecols = [1],\n",
    "                      engine = \"python\",\n",
    "                      skipfooter = 3)\n",
    "\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'data'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-15-21b3f857f92c>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mmodel\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mNBeats\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mdata\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mdf\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mperiod_to_forecast\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m10\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m      2\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mfit\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[0mforecast\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      4\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Videos\\BetaSci\\venv38\\lib\\site-packages\\pytorch_forecasting\\models\\nbeats\\__init__.py\u001B[0m in \u001B[0;36m__init__\u001B[1;34m(self, stack_types, num_blocks, num_block_layers, widths, sharing, expansion_coefficient_lengths, prediction_length, context_length, dropout, learning_rate, log_interval, log_gradient_flow, log_val_interval, weight_decay, loss, reduce_on_plateau_patience, backcast_loss_ratio, logging_metrics, **kwargs)\u001B[0m\n\u001B[0;32m     89\u001B[0m             \u001B[0mloss\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mMASE\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     90\u001B[0m         \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msave_hyperparameters\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 91\u001B[1;33m         \u001B[0msuper\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__init__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mloss\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mlogging_metrics\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mlogging_metrics\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     92\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     93\u001B[0m         \u001B[1;31m# setup stacks\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mTypeError\u001B[0m: __init__() got an unexpected keyword argument 'data'"
     ]
    }
   ],
   "source": [
    "model = NBeats(data=df, period_to_forecast=10)\n",
    "model.fit()\n",
    "forecast = model.predict()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'time_idx'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-6-6cf3fec711e6>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mtraining_cutoff\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m582\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m training = TimeSeriesDataSet(\n\u001B[1;32m----> 9\u001B[1;33m  \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime_idx\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mtraining_cutoff\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m  \u001B[0mtime_idx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"time_idx\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m  \u001B[0mtarget\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"volume\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Videos\\BetaSci\\venv38\\lib\\site-packages\\pandas\\core\\frame.py\u001B[0m in \u001B[0;36m__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   2987\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__getitem__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2988\u001B[0m         \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mlib\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mitem_from_zerodim\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 2989\u001B[1;33m         \u001B[0mkey\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcom\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mapply_if_callable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   2990\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   2991\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mis_hashable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mkey\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Videos\\BetaSci\\venv38\\lib\\site-packages\\pandas\\core\\common.py\u001B[0m in \u001B[0;36mapply_if_callable\u001B[1;34m(maybe_callable, obj, **kwargs)\u001B[0m\n\u001B[0;32m    327\u001B[0m     \"\"\"\n\u001B[0;32m    328\u001B[0m     \u001B[1;32mif\u001B[0m \u001B[0mcallable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmaybe_callable\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 329\u001B[1;33m         \u001B[1;32mreturn\u001B[0m \u001B[0mmaybe_callable\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mobj\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    330\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    331\u001B[0m     \u001B[1;32mreturn\u001B[0m \u001B[0mmaybe_callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<ipython-input-6-6cf3fec711e6>\u001B[0m in \u001B[0;36m<lambda>\u001B[1;34m(x)\u001B[0m\n\u001B[0;32m      7\u001B[0m \u001B[0mtraining_cutoff\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;36m582\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      8\u001B[0m training = TimeSeriesDataSet(\n\u001B[1;32m----> 9\u001B[1;33m  \u001B[0mdata\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;32mlambda\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtime_idx\u001B[0m \u001B[1;33m<=\u001B[0m \u001B[0mtraining_cutoff\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     10\u001B[0m  \u001B[0mtime_idx\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"time_idx\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     11\u001B[0m  \u001B[0mtarget\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;34m\"volume\"\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m~\\Videos\\BetaSci\\venv38\\lib\\site-packages\\pandas\\core\\generic.py\u001B[0m in \u001B[0;36m__getattr__\u001B[1;34m(self, name)\u001B[0m\n\u001B[0;32m   5463\u001B[0m             \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_info_axis\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_can_hold_identifiers_and_holds_name\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5464\u001B[0m                 \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m[\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 5465\u001B[1;33m             \u001B[1;32mreturn\u001B[0m \u001B[0mobject\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m__getattribute__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   5466\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   5467\u001B[0m     \u001B[1;32mdef\u001B[0m \u001B[0m__setattr__\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mname\u001B[0m\u001B[1;33m:\u001B[0m \u001B[0mstr\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mvalue\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;33m->\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'DataFrame' object has no attribute 'time_idx'"
     ]
    }
   ],
   "source": [
    "from pytorch_forecasting.data import (\n",
    " TimeSeriesDataSet,\n",
    " GroupNormalizer\n",
    ")\n",
    "max_prediction_length = 195  # forecast of 195 days\n",
    "max_encoder_length = 780  # using history of 582 days\n",
    "training_cutoff = 582\n",
    "training = TimeSeriesDataSet(\n",
    " data[lambda x: x.time_idx <= training_cutoff],\n",
    " time_idx=\"time_idx\",\n",
    " target=\"volume\",\n",
    " group_ids=[\"agency\", \"sku\"],\n",
    " min_encoder_length=0,  # allowing predictions without history\n",
    "max_encoder_length=max_encoder_length,\n",
    " min_prediction_length=1,\n",
    " max_prediction_length=max_prediction_length,\n",
    " static_categoricals=[\"agency\", \"sku\"],\n",
    " static_reals=[\n",
    "     \"avg_population_2017\",\n",
    "     \"avg_yearly_household_income_2017\"\n",
    " ],\n",
    "time_varying_known_categoricals=[\"special_days\", \"month\"],\n",
    " # group of categorical variables can be treated as one variable\n",
    " variable_groups={\"special_days\": special_days},\n",
    " time_varying_known_reals=[\n",
    "     \"time_idx\",\n",
    "     \"price_regular\",\n",
    "     \"discount_in_percent\"\n",
    " ],\n",
    " time_varying_unknown_categoricals=[],\n",
    " time_varying_unknown_reals=[\n",
    "     \"volume\",\n",
    "     \"log_volume\",\n",
    "     \"industry_volume\",\n",
    "     \"soda_volume\",\n",
    "     \"avg_max_temp\",\n",
    "     \"avg_volume_by_agency\",\n",
    "     \"avg_volume_by_sku\",\n",
    " ],\n",
    " target_normalizer=GroupNormalizer(\n",
    "     groups=[\"agency\", \"sku\"], coerce_positive=1.0\n",
    " ),  # use softplus with beta=1.0 and normalize by group\n",
    " add_relative_time_idx=True,  # add as feature\n",
    " add_target_scales=True,  # add as feature\n",
    " add_encoder_length=True,  # add as feature\n",
    ")\n",
    "# creating validation set (predict=True) which means to predict the\n",
    "# last max_prediction_length points in time for each series\n",
    "validation = TimeSeriesDataSet.from_dataset(\n",
    " training, data, predict=True, stop_randomization=True\n",
    ")\n",
    "# create dataloaders for model\n",
    "batch_size = 128\n",
    "train_dataloader = training.to_dataloader(\n",
    " train=True, batch_size=batch_size, num_workers=0\n",
    ")\n",
    "val_dataloader = validation.to_dataloader(\n",
    " train=False, batch_size=batch_size * 10, num_workers=0\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyCharm (BetaSci)",
   "language": "python",
   "name": "pycharm-6936f044"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}